---
title: "TP1 sondage"
author: "Jossaud Fabien"
date: "15/01/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Exercice 1 

Pour cette exercice on va créer la fonction questionDelicateMeth1 qui génère des simulations de réponses selon la méthode de Warner : 

```{r}
questDelicateMeth1 <- function(n, P, theta, n.sim, p.neg=0)
{P.chap <- rep(NA,n.sim)
P <- (1-p.neg)*P
for(i in 1:n.sim){
  # Choix de la question
  question <- sample(c(1,2),n,prob=c(theta,1-theta),replace=TRUE)
  # Choix du répondant
  repondant <- sample(c(1,2),n,prob=c(P,1-P),replace=TRUE)
  #
  nb.oui <- sum(question-repondant==0)
  P.chap[i] <- (nb.oui/n+theta-1)/(2*theta-1)
}
return(P.chap=P.chap)
}
```

On va ensuite faire 1000 simulations de la méthode avec n=500 et theta=0.8 

```{r}
N <- 1000
n <- 500
theta <- 0.8 
P <- 0.1
set.seed(2010)
Warner1 <- questDelicateMeth1(n,P,theta,N)

```

## a 

```{r}
moy1 <- mean(Warner1)
sd1 <- sqrt(var(Warner1))
```

## b

Logiquement, on devrait avoir une moyenne à 0.10 ($\pi_{A}$) et un écart-type à 0 

## c 

Si toutes les personnes répondent directement honnetement, le sondage correspond à une loi binomiale avec n=500 et p=0.1 

```{r}
set.seed(2010)
simubino <- rbinom(N,n,P)/n
varbino1 <- var(simubino)
varWarner1 <- var(Warner1)
```

Il y a une différence entre les 2 variances. En effet, même si c'est minime, la méthode direct est plus précise que la méthode de Werner à condition que la population réponde honnêtement. 

## d

```{r}
hist(Warner1,main="Simulations avec la méthode de Warner")
```

## e

On remarque que la méthode de Warner se rapproche assez bien de ce qu'on espère obtenir, mais moins proche que si les gens répondent directement et honnêtement au sondage. 

# Exercice 2 

```{r}
questDelicateMeth2 <- function(n, P, theta, alpha, n.sim, p.neg=0)
{P.chap <- rep(NA,n.sim)
P <- (1-p.neg)*P
for(i in 1:n.sim){
  # Choix de la question
  question <- sort(sample(c(1,2),n,prob=c(theta,1-theta),replace=TRUE))
  # La question étant choisie, à qui s'adresse-t-elle ?
  nb.1 <- sum(question==1)
  nb.oui <- sum(sample(c(1,2),nb.1,prob=c(P,1-P),replace=TRUE)==1)+
    sum(sample(c(1,2),n-nb.1,prob=c(alpha,1-alpha),replace=TRUE)==1)
  P.chap[i] <- (nb.oui/n-(1-theta)*alpha)/(theta)
}
return(P.chap=P.chap)
}
```

On va ensuite faire 1000 simulations de la méthode avec n=500, theta=0.8 et alpha=0.217

```{r}
N <- 1000
n <- 500
theta <- 0.8 
alpha <- 0.217
P <- 0.1 
set.seed(2010)
Meth2 <- questDelicateMeth2(n,P,theta,alpha,N)

```

## a 

```{r}
moy2 <- mean(Meth2)
sd2 <- sqrt(var(Meth2))
```

## b 

On a toujours 0.10 et 0 en valeurs attendues

## c 

```{r}
varMeth2 <- var(Meth2)
```

On remarque toujours une différence entre les 2 méthodes même si elle est encore plus infime que pour Werner. 

## d 

```{r}
hist(Meth2,main="Simulations avec la 2nde méthode")
```

## e

On remarque que, dans notre cas, la variance est significativement plus précise que pour Warner mais la moyenne s'éloigne de la valeur espérée. 

# Exercice 3 

## 0 %
```{r}
eqmMeth2 <- var(Meth2) + (mean(Meth2)-P)^2
eqmWarner0 <- var(Warner1) + (mean(Warner1)-P)^2
```

Dans le cas où personnes ne nient , la Méthode 2 possède la plus petite EQM 

## 10 % 

```{r}
set.seed(2010)
Warner10 <- questDelicateMeth1(n,P,theta,N,0.1)

eqmWarner10 <- var(Warner10) + (mean(Warner10)-P)^2
```

## 20 % 

```{r}
set.seed(2010)
Warner20 <- questDelicateMeth1(n,P,theta,N,0.2)

eqmWarner20 <- var(Warner20) + (mean(Warner20)-P)^2
```

## 30 % 

```{r}
set.seed(2010)
Warner30 <- questDelicateMeth1(n,P,theta,N,0.3)

eqmWarner30 <- var(Warner30) + (mean(Warner30)-P)^2
```

## 40 % 

```{r}
set.seed(2010)
Warner40 <- questDelicateMeth1(n,P,theta,N,0.4)

eqmWarner40 <- var(Warner40) + (mean(Warner40)-P)^2
```

On remarque que , quelque soit le pourcentages de négation, la 2è méthode reste la plus fiable ( ce qui est logique car , comme indiqué page 3, la variance de la 2è méthode est plus faible à partir du moment ou $\theta$ > 1/3 )

# Exercice 4 

## a

```{r}
pop <- c(3, 6, 24, 27, 30, 36, 51, 57)
N <- length(pop)
yu <- mean(pop)
S <- sd(pop)
```

## b

```{r}
options(OutDec = ",")
n <- 3
(n.ech <- choose(N,n))
ech.all <- cbind(choix <- t(matrix(combn(1:N,n),n,n.ech)),(matrix(pop[choix],n.ech,n)))	
rownames(ech.all) <- seq(1:nrow(ech.all))
colnames(ech.all) <- c(paste("i",1:n,sep=""),paste("pop[i",1:n,"]",sep=""))
head(ech.all)
```

## c 

```{r}
ybar <-( ech.all[,4] + ech.all[,5] + ech.all[,6] ) / 3
s<-apply(ech.all[,4:6],1,function(i){sqrt(var(i))})
s<-apply(ech.all[,4:6],1,function(i){sqrt(var(i))})
b.inf <- ybar - 1.96*sqrt((1-n/N)*(s^2/n))
b.sup <- ybar + 1.96*sqrt((1-n/N)*(s^2/n))
for (i in 1:56) {if(yu<b.sup[i] && yu>b.inf[i]){include[i] <- 1} else {include[i] <- 0}}
ech.all<-cbind(ybar,s,b.inf,b.sup,include,ech.all)
```

## d 

```{r}
muybar <- mean(ybar)
muybar == yu
```
On a bien $\mu_{\bar{y}}$ = $\bar{y}_\mathcal{U}$ 

```{r}
sigmaybarth <- sqrt(1-n/N)*(S/sqrt(n))
sigmaybar <- sd(ybar)*sqrt((length(ybar)-1)/length(ybar))
```

On a bien $\sigma_{\bar{y}}$ = $\sqrt{1 - f}\frac{S}{\sqrt{n}}$

## e 

```{r}
mean(s) - S
```

Le biais n'est donc pas nul 

## f 

```{r}
ech.all <- as.data.frame(ech.all)
erreur_2<-unlist(lapply(ech.all$ybar,function(i){if (abs(i-yu)>2) {1}else{0}}))
proba_2<-sum(erreur_2)/length(erreur_2)

erreur_5<-unlist(lapply(ech.all$ybar,function(i){if (abs(i-yu)>5) {1}else{0}}))
proba_5<-sum(erreur_5)/length(erreur_5)

erreur_25<-unlist(lapply(ech.all$ybar,function(i){if (abs(i-yu)>yu/4) {1}else{0}}))
proba_25<-sum(erreur_25)/length(erreur_25)
```

## g

```{r}
erreur_20<-unlist(lapply(ech.all$s,function(i){if (abs(i-S)>S/5) {1}else{0}}))
proba_20<-sum(erreur_20)/length(erreur_20)
```

## h 


